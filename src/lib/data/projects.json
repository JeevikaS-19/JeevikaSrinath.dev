[
    {
        "id": "hand-gesture-drawing",
        "title": "Hand Gesture Drawing App",
        "role": "Lead Developer",
        "categories": [
            "Python projects"
        ],
        "description": "A real-time computer vision tool that maps spatial coordinates between hands to create dynamic vector lines.",
        "tech_stack": [
            "Python",
            "OpenCV",
            "MediaPipe"
        ],
        "thumbnail": "/images/hand-draw-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Python-Projects-.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Coordinate mapping from Landmark #8 (Index Tip) to OpenCV line rendering.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Webcam Feed",
                        "details": "Captures raw video frames at 30FPS using OpenCV's VideoCapture module."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 50
                    },
                    "data": {
                        "label": "MediaPipe Landmark Detection",
                        "details": "Processes frames to identify 21 3D hand landmarks using pre-trained ML models."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 150
                    },
                    "data": {
                        "label": "Isolate Index Tip (#8)",
                        "details": "Filters landmark data to focus exclusively on the X/Y coordinates of the index finger tip."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 100
                    },
                    "data": {
                        "label": "cv2.line Vectoring",
                        "details": "Draws continuous lines between sequential coordinates on a persistent digital canvas."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "gesture-accumulator",
        "title": "Gesture Stability Accumulator",
        "role": "Lead Developer",
        "categories": [
            "Python projects"
        ],
        "description": "An intelligent counter that uses temporal stability filters to process noisy sensor data into stable numerical inputs.",
        "tech_stack": [
            "Python",
            "OpenCV",
            "MediaPipe",
            "Logic State Management"
        ],
        "thumbnail": "/images/counter-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Python-Projects-.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "3-Frame buffer logic ensuring gesture stability before data accumulation.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Hand Detection",
                        "details": "Initial detection of hand presence and orientation in the frame."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "Finger Count Logic",
                        "details": "Analyzes the relative positions of finger tips to base joints to determine count."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 50
                    },
                    "data": {
                        "label": "Stability Buffer (3 Frames)",
                        "details": "Requires the same count for 3 consecutive frames before triggering an update."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 100
                    },
                    "data": {
                        "label": "Global Sum Accumulator",
                        "details": "Updates a global state variable with the validated finger count increment."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "air-drawing-canvas",
        "title": "Air Drawing Canvas",
        "role": "Lead Developer",
        "categories": [
            "Python projects"
        ],
        "description": "An AR-style drawing interface using hand gestures for tool switching, erasing, and canvas management.",
        "tech_stack": [
            "Python",
            "OpenCV",
            "NumPy",
            "MediaPipe"
        ],
        "thumbnail": "/images/air-draw-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Building_blocks.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "State-machine logic mapping specific hand gestures to canvas operations.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Gesture Recognition",
                        "details": "Classifies hand shapes (e.g., closed fist, open palm) into control signals."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "Decision: Draw / Erase / Clear",
                        "details": "Logic branch that dictates which NumPy operation to apply to the pixel matrix."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 220px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 550,
                        "y": 50
                    },
                    "data": {
                        "label": "NumPy Array Canvas",
                        "details": "A 2D matrix representing the drawing surface where values are modified in real-time."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 800,
                        "y": 100
                    },
                    "data": {
                        "label": "Weighted Frame Overlay",
                        "details": "Blends the drawn canvas with the live webcam feed using cv2.addWeighted."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "sudoku-recursive-solver",
        "title": "Recursive Sudoku Engine",
        "role": "Algorithm Engineer",
        "categories": [
            "Python projects"
        ],
        "description": "A high-performance backtracking algorithm that solves any valid Sudoku puzzle through depth-first search.",
        "tech_stack": [
            "Python (Standard Library)"
        ],
        "thumbnail": "/images/sudoku-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Python-Projects-.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Recursive backtracking loop: Place -> Validate -> Recursion or Backtrack.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 150
                    },
                    "data": {
                        "label": "Find Empty Cell",
                        "details": "Scans the grid for the first zero-value cell to begin the trial process."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 150
                    },
                    "data": {
                        "label": "Iterate 1-9",
                        "details": "Cycles through possible numbers for the current cell as candidate solutions."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 140px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 450,
                        "y": 150
                    },
                    "data": {
                        "label": "Constraint Check",
                        "details": "Verifies if the candidate number violates row, column, or 3x3 grid rules."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 700,
                        "y": 150
                    },
                    "data": {
                        "label": "Backtrack (Undo)",
                        "details": "Resets the cell if no number fits and returns to the previous recursion depth."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "label": "Invalid",
                    "animated": false,
                    "style": "stroke: #ef4444; stroke-dasharray: 5,5;"
                },
                {
                    "id": "e3-1",
                    "source": "3",
                    "target": "1",
                    "label": "Valid",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "emptydatfridge",
        "title": "EmptyDatFridge",
        "role": "Full Stack Developer",
        "categories": [
            "Websites"
        ],
        "description": "A recipe discovery engine that optimizes household food waste by matching available ingredients to professional recipes.",
        "tech_stack": [
            "SvelteKit",
            "Tailwind CSS",
            "Recipe API",
            "Google Search Console"
        ],
        "thumbnail": "/images/fridge-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/FlavorGenie.git",
            "live": "https://emptydatfridge.com/"
        },
        "blueprint": {
            "flow_description": "Ingredient parsing logic to API query matching.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "User Ingredient Input",
                        "details": "Accepts comma-separated text or selected tags representing pantry items."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 50
                    },
                    "data": {
                        "label": "Search Logic & Filtering",
                        "details": "Processes input strings into optimized search terms for external API consumption."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 100
                    },
                    "data": {
                        "label": "API Fetch",
                        "details": "Asynchronous request to recipe database returning JSON payloads of matching dishes."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 140px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 700,
                        "y": 100
                    },
                    "data": {
                        "label": "Dynamic Recipe Cards",
                        "details": "Renders returned data into responsive UI components with images and health labels."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "scrapbook",
        "title": "Scrapbook",
        "role": "Lead UI/UX Developer",
        "categories": [
            "Websites"
        ],
        "description": "A Gen Z inspired digital photobooth featuring vintage filters, sticker overlays, and a scrapbook layout editor.",
        "tech_stack": [
            "React/Svelte",
            "CSS Filters",
            "Canvas API"
        ],
        "thumbnail": "/images/scrapbook-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/scrapbook.git",
            "live": "https://scrapbook-azure.vercel.app/"
        },
        "blueprint": {
            "flow_description": "Digital darkroom processing from raw image to aesthetic scrapbook page.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Webcam Capture",
                        "details": "Interfaces with standard browser navigator.mediaDevices for live video stream."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "Aesthetic Filter Layer",
                        "details": "Applies custom CSS filters (grain, sepia, high contrast) via React component wrappers."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 50
                    },
                    "data": {
                        "label": "Drag-and-Drop Stickers",
                        "details": "Uses absolute positioning and event listeners to allow free-form layout editing."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 100
                    },
                    "data": {
                        "label": "Final Scrapbook Export",
                        "details": "Converts the DOM state into a downloadable image using html2canvas logic."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "pacman-python",
        "title": "Pac-Man Game",
        "role": "Game Developer",
        "categories": [
            "Python projects"
        ],
        "description": "A classic arcade simulation built using Python and Pygame. The project focuses on game loop management, collision detection, and basic AI pathfinding for ghosts.",
        "tech_stack": [
            "Python",
            "Pygame",
            "AI Pathfinding"
        ],
        "thumbnail": "/images/pacman-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Python-Projects-.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Game loop cycle managing entity updates, collision checks, and AI state transitions.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Game Loop",
                        "details": "The core infinite while loop that controls timing (FPS) and event handling."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 140px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 200,
                        "y": 50
                    },
                    "data": {
                        "label": "Tile Map Parser",
                        "details": "Translates text-based grid representations into coordinate-based barrier objects."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 200,
                        "y": 150
                    },
                    "data": {
                        "label": "Entity Manager",
                        "details": "Tracks position, velocity, and state for Pac-Man and all four ghost entities."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                },
                {
                    "id": "4",
                    "type": "default",
                    "position": {
                        "x": 450,
                        "y": 100
                    },
                    "data": {
                        "label": "Collision System",
                        "details": "Detects overlaps between pixel-based rectangles to trigger game events like death or scoring."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "5",
                    "type": "output",
                    "position": {
                        "x": 700,
                        "y": 100
                    },
                    "data": {
                        "label": "Ghost AI (State Machine)",
                        "details": "Controls movement logic based on current state: Chase, Scatter, or Frightened."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e1-3",
                    "source": "1",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-4",
                    "source": "2",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e4-5",
                    "source": "4",
                    "target": "5",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "architect-bot",
        "title": "Architect Bot",
        "role": "AI Engineer",
        "categories": [
            "On going"
        ],
        "description": "An AI-powered design-to-code tool that utilizes Computer Vision to analyze hand-drawn wireframes and Gemini API to generate clean, stylized digital mockups.",
        "tech_stack": [
            "Python",
            "OpenCV",
            "Gemini API",
            "Generative AI"
        ],
        "thumbnail": "/images/architect-thumb.jpg",
        "links": {
            "repo": "",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Transformation pipeline: Sketch -> CV Analysis -> Layout Mapping -> Generative Code.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Hand-Drawn Sketch",
                        "details": "Input image of wireframes drawn on paper or whiteboard."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "Shape Detection (CV)",
                        "details": "Uses contour detection to identify bounding boxes for buttons, images, and text areas."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 50
                    },
                    "data": {
                        "label": "Layout Grid Mapper",
                        "details": "Aligns detected shapes to a flexible grid system to maintain spatial relationships."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 100
                    },
                    "data": {
                        "label": "Gemini Generator",
                        "details": "Sends coordinates and layout data to Gemini API to produce modern Tailwind/HTML code."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    },
    {
        "id": "squash-sensei",
        "title": "Squash Sensei",
        "role": "CV Engineer",
        "categories": [
            "On going"
        ],
        "description": "A sports-analytics tool built with MediaPipe to analyze player habits and movement efficiency on a squash court via pose estimation.",
        "tech_stack": [
            "Python",
            "MediaPipe",
            "OpenCV",
            "Data Analytics"
        ],
        "thumbnail": "/images/squash-thumb.jpg",
        "links": {
            "repo": "",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Data pipeline processing video feed into T-Position heatmaps and stroke classification logs.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Court Video Feed",
                        "details": "Fixed-angle video recording of a squash match."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "MediaPipe Pose (33 LM)",
                        "details": "Real-time keypoint extraction for the player's skeleton to track movement."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 550,
                        "y": 50
                    },
                    "data": {
                        "label": "T-Position Heatmap",
                        "details": "Aggregates player positions over time to visualize court coverage efficiency."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 550,
                        "y": 150
                    },
                    "data": {
                        "label": "Stroke Classifier",
                        "details": "Heuristic model that identifies backhands and forehands based on joint angles."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e2-4",
                    "source": "2",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                }
            ]
        }
    },
    {
        "id": "bluetooth-messenger",
        "title": "Bluetooth Messenger",
        "role": "Full Stack Developer",
        "categories": [
            "Python projects"
        ],
        "description": "A secure, cross-platform Bluetooth messaging application for Android and Windows. Features RAM-only storage with 5-minute auto-deletion for enhanced privacy.",
        "tech_stack": [
            "Python",
            "Kivy",
            "PyBluez",
            "Cross-Platform"
        ],
        "thumbnail": "/images/bluetooth-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/Bluetooth_msgs.git",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Peer-to-peer message synchronization over Bluetooth RFCOMM channels.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Bluetooth Scan",
                        "details": "Discovers nearby Bluetooth-enabled devices using PyBluez inquiries."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 50
                    },
                    "data": {
                        "label": "PIN Authentication",
                        "details": "Enforces a common 6-digit PIN shared between host and client for connection security."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 160px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 100
                    },
                    "data": {
                        "label": "RAM Message Buffer",
                        "details": "Stores incoming and outgoing strings in system memory to avoid disk forensics."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 160px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 100
                    },
                    "data": {
                        "label": "5-Min Auto Eraser",
                        "details": "A timed thread that purges localized buffers to maintain high privacy standards."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #ef4444; color: #fff; width: 160px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #ef4444;"
                }
            ]
        }
    },
    {
        "id": "mclaren-strategy",
        "title": "The McLaren Strategy",
        "role": "Strategic Researcher",
        "categories": [
            "Research",
            "On going"
        ],
        "description": "An investigative research project analyzing the transferability of McLaren Racing’s 'Race Operations' framework to non-automotive sectors.",
        "tech_stack": [
            "F1 Telemetry",
            "Data Analytics",
            "Systems Engineering"
        ],
        "thumbnail": "/images/mclaren-thumb.jpg",
        "links": {
            "repo": "",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Data acquisition from high-stakes racing telemetry into cross-domain industrial logic.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Data Acquisition (F1 Telemetry)",
                        "details": "Real-time stream of 1000+ data points per second from vehicle sensors."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 220px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 300,
                        "y": 100
                    },
                    "data": {
                        "label": "Pattern Extraction",
                        "details": "Identifying high-stakes bottlenecks and recurring failures in the data flow."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 550,
                        "y": 100
                    },
                    "data": {
                        "label": "Algorithmic Mapping",
                        "details": "Translating racing logic into industrial supply chain or medical diagnostic models."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 200px;"
                },
                {
                    "id": "4",
                    "type": "default",
                    "position": {
                        "x": 800,
                        "y": 50
                    },
                    "data": {
                        "label": "Logistics/Healthcare Application",
                        "details": "Deploying the model to optimize real-world critical decision systems."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 220px;"
                },
                {
                    "id": "5",
                    "type": "output",
                    "position": {
                        "x": 800,
                        "y": 150
                    },
                    "data": {
                        "label": "Efficiency Feedback Loop",
                        "details": "Iterative refinement of the model based on real-world performance metrics."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 200px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e4-5",
                    "source": "4",
                    "target": "5",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                }
            ]
        },
        "full_report": "Report 1: The McLaren Framework\nProject Title: Operational Synchronicity: Applying F1 Telemetry Logic to System Architecture Status: Ongoing Research / Technical Paper\nFocus: Industrial Optimization & Concurrency\n\n1. Executive Summary\nThis research investigates the transition of Formula 1 \"Race Operations\" logic into high-consequence software environments. The study focuses on how McLaren’s use of sub-second telemetry loops and pit-stop synchronization can be abstracted to solve resource-blocking in multi-threaded computing systems.\n\n2. Research Focus\n* The Pit-Stop Analogy: Developing a framework where system updates or \"maintenance windows\" are treated as F1 pit stops—high-speed, synchronized, and zero-error.\n* Telemetry Integration: Implementing real-time feedback loops that adjust system parameters dynamically, similar to how an F1 car adjusts engine mapping based on live track data.\n\n3. Methodology (The Flow)\n1. Extraction: Identifying core \"Race Logic\" variables from McLaren Applied case studies.\n2. Mapping: Translating mechanical \"pit-stop\" variables into software \"uptime\" parameters.\n3. Simulated Execution: Testing the logic against high-load data environments.\n4. Optimization: Finalizing the \"Telemetry-to-Task\" (T2T) architecture."
    },
    {
        "id": "cyber-evolution",
        "title": "Cyber-Evolution",
        "role": "Cybersecurity Researcher",
        "categories": [
            "Research",
            "On going"
        ],
        "description": "A technical research paper charting the morphological evolution of cybersecurity threats and vulnerability lifecycles.",
        "tech_stack": [
            "Cybersecurity",
            "Threat Modeling",
            "AI / ML"
        ],
        "thumbnail": "/images/cyber-thumb.jpg",
        "links": {
            "repo": "",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Charting the lifecycle of vulnerabilities from discovery to predictive defense modeling.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Initial Discovery",
                        "details": "Identification of zero-day or legacy exploits in established systems."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 100
                    },
                    "data": {
                        "label": "Patch Deployment",
                        "details": "Systemic response to mitigate the vulnerability across affected nodes."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 500,
                        "y": 50
                    },
                    "data": {
                        "label": "Attacker Adaptation",
                        "details": "The morphological shift of the exploit to bypass new defensive measures."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 200px;"
                },
                {
                    "id": "4",
                    "type": "default",
                    "position": {
                        "x": 750,
                        "y": 50
                    },
                    "data": {
                        "label": "New Vector Emergence",
                        "details": "Identification of the secondary threat resulting from the initial adaptation."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                },
                {
                    "id": "5",
                    "type": "output",
                    "position": {
                        "x": 750,
                        "y": 150
                    },
                    "data": {
                        "label": "Predictive Defense Modeling",
                        "details": "Algorithmically forecasting future exploits based on past evolutionary data."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 220px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e4-5",
                    "source": "4",
                    "target": "5",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                }
            ]
        },
        "full_report": "Report 2: Cybersecurity Evolution & Morphology\nProject Title: The Vulnerability Matrix: A Predictive Model for Morphological Cyber-Threats Status: Deep-Dive Analysis / Simulation Project\nFocus: Security Architecture & Threat Modeling\n\n1. Executive Summary\nThis paper charts the DNA of cybersecurity vulnerabilities from legacy exploits to modern AI-driven intrusions. The core research identifies a \"Morphological Gap\"—a space where existing security frameworks fail to adapt as quickly as the threats themselves.\n\n2. Research Focus\n* Lifecycle Mapping: Tracking the evolution of \"Buffer Overflow\" and \"Injection\" attacks into sophisticated, AI-automated social engineering and API exploits.\n* The Simulation Model: Development of a proactive defense environment that uses historical exploit data to predict the next logical move of a threat actor.\n\n3. Methodology (The Flow)\n1. Historical Audit: Data collection from CVE databases (2020-2026).\n2. Gap Analysis: Identifying \"Blind Spots\" in current Zero-Trust architectures.\n3. Simulation: Running \"Red Team\" scripts in a controlled environment to observe vulnerability adaptation.\n4. Defense Protocol: Drafting a \"Proactive Resistance\" framework."
    },
    {
        "id": "vibe-coding",
        "title": "Vibe Coding",
        "role": "Methodology Researcher",
        "categories": [
            "Research",
            "On going"
        ],
        "description": "A methodology-focused paper defining 'Vibe Coding'—a high-abstraction development paradigm involving Human-AI symbiosis.",
        "tech_stack": [
            "LLMs",
            "Software Architecture",
            "AI Ethics"
        ],
        "thumbnail": "/images/vibe-thumb.jpg",
        "links": {
            "repo": "",
            "live": ""
        },
        "blueprint": {
            "flow_description": "Transforming abstract intent into modular, scalable systems through AI orchestration.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Conceptual Intent (The Vibe)",
                        "details": "Defining high-level project goals and aesthetic vision in natural language."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 220px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 300,
                        "y": 100
                    },
                    "data": {
                        "label": "AI-Generated Prototype",
                        "details": "Rapid instantiation of code structures using Large Language Models."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 550,
                        "y": 100
                    },
                    "data": {
                        "label": "Human-Led Refinement",
                        "details": "Architectural oversight and quality auditing of AI outputs."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "4",
                    "type": "default",
                    "position": {
                        "x": 800,
                        "y": 50
                    },
                    "data": {
                        "label": "Modular Integration",
                        "details": "Synthesizing individual components into a cohesive, production-ready system."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 220px;"
                },
                {
                    "id": "5",
                    "type": "output",
                    "position": {
                        "x": 800,
                        "y": 150
                    },
                    "data": {
                        "label": "Continuous Iteration",
                        "details": "Fast-feedback loops using AI to maintain and scale the existing architecture."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 200px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e4-5",
                    "source": "4",
                    "target": "5",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                }
            ]
        },
        "full_report": "Report 3: The Vibe Coding Audit\nProject Title: The Pseudo-Code Trap: Security Auditing in Intent-Based Development Status: Methodology Development / Best Practices Paper\nFocus: Human-AI Interaction & Secure Engineering\n\n1. Executive Summary\nAs development shifts toward \"Vibe Coding\" (natural language intent), the risk of \"Pseudo-code Traps\" increases. This research audits the security integrity of AI-generated code, focusing on how developers can maintain professional standards while utilizing high-speed AI tools.\n\n2. Research Focus\n* The \"Vibe\" Verification: Designing a verification layer that sits between the LLM output and the production environment.\n* Clean Vibe Checklist: A proprietary set of 12 security checkpoints designed to catch hallucinated vulnerabilities, hardcoded secrets, and inefficient logic before deployment.\n\n3. Methodology (The Flow)\n1. Intent Input: Documenting the \"Prompt to Code\" ratio in modern dev workflows.\n2. Trap Identification: Manually auditing 50+ AI-generated components for common security anti-patterns.\n3. Checklist Integration: Applying the \"Clean Vibe\" filters to the workflow.\n4. Final Validation: Benchmarking the security score of audited code vs. raw AI output."
    },
    {
        "id": "ghostbox",
        "title": "GhostBox",
        "role": "Lead Developer & Security Architect",
        "categories": [
            "Websites"
        ],
        "description": "A hardened, E2E encrypted, Windows 95-inspired chat experience. Features AES-256-GCM encryption, Supabase Realtime synchronization, and a custom Win95-styled UI component engine.",
        "tech_stack": [
            "React 19",
            "TypeScript",
            "Tailwind CSS",
            "Supabase Realtime",
            "Web Crypto API"
        ],
        "thumbnail": "/images/ghostbox-thumb.jpg",
        "links": {
            "repo": "https://github.com/JeevikaS-19/GhostBox.git",
            "live": "https://ghost-box-beta.vercel.app/"
        },
        "blueprint": {
            "flow_description": "Encryption handshake and real-time message propagation through Supabase edge nodes.",
            "nodes": [
                {
                    "id": "1",
                    "type": "input",
                    "position": {
                        "x": 0,
                        "y": 100
                    },
                    "data": {
                        "label": "Client Handshake",
                        "details": "Local derivation of AES-256-GCM keys from user-provided passphrase. Keys never leave the browser."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 180px;"
                },
                {
                    "id": "2",
                    "type": "default",
                    "position": {
                        "x": 250,
                        "y": 50
                    },
                    "data": {
                        "label": "Web Crypto Encryption",
                        "details": "Converts plain-text messages into encrypted cipher-text using the locally derived initialization vector (IV)."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 200px;"
                },
                {
                    "id": "3",
                    "type": "default",
                    "position": {
                        "x": 550,
                        "y": 100
                    },
                    "data": {
                        "label": "Supabase Realtime Sync",
                        "details": "Broadcasts high-priority cipher-text payloads to authenticated room members over PostgreSQL CDC channels."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #2a9d8f; color: #fff; width: 220px;"
                },
                {
                    "id": "4",
                    "type": "output",
                    "position": {
                        "x": 800,
                        "y": 100
                    },
                    "data": {
                        "label": "Win95 UI Terminal",
                        "details": "Renders decrypted streams into a retro-styled chat buffer with CRT scanline overlays."
                    },
                    "style": "background: #0d0d0d; border: 1px solid #e9c46a; color: #fff; width: 180px;"
                }
            ],
            "edges": [
                {
                    "id": "e1-2",
                    "source": "1",
                    "target": "2",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                },
                {
                    "id": "e2-3",
                    "source": "2",
                    "target": "3",
                    "animated": true,
                    "style": "stroke: #e9c46a;"
                },
                {
                    "id": "e3-4",
                    "source": "3",
                    "target": "4",
                    "animated": true,
                    "style": "stroke: #2a9d8f;"
                }
            ]
        }
    }
]